TEMP_TAR_GZ_FILENAME = '/tmp/fairing.layer.tar.gz'
DEFAULT_IMAGE_NAME = 'fairing-job'
DEFAULT_BASE_IMAGE = 'gcr.io/kubeflow-images-public/fairing:dev'
DEFAULT_REGISTRY = 'index.docker.io'
DEFAULT_DEST_PREFIX = '/app/'

DEFAULT_CONTEXT_FILENAME = '/tmp/fairing.context.tar.gz'
DEFAULT_GENERATED_DOCKERFILE_FILENAME = '/tmp/Dockerfile'

GOOGLE_CREDS_ENV = 'GOOGLE_APPLICATION_CREDENTIALS'
GCP_CREDS_SECRET_NAME = 'user-gcp-sa'

AWS_CREDS_SECRET_NAME = 'aws-secret'

# This secret contains Azure credentials for a service principal with access to required Azure resources.
# To generate a credentials file for a service principal we may do the following:
#    SUBSCRIPTION_ID=...
#    RESOURCE_GROUP=...
#    FILE_NAME=...
#    az ad sp create-for-rbac --scope /subscriptions/${SUBSCRIPTION_ID}/resourceGroups/${RESOURCE_GROUP} --sdk-auth > ${FILE_NAME}
# To set a secret in k8s cluster containing the credentials file:
#    NAMESPACE=...
#    SECRET_NAME=...
#    kubectl create secret generic -n ${NAMESPACE} ${SECRET_NAME} --from-file=azure-credentials.json=${FILE_NAME}
AZURE_CREDS_SECRET_NAME = 'azure-credentials'

# The secret containing credentials to access a specific storage account is dynamically generated by using Azure credentials to get those storage credentials.
AZURE_STORAGE_CREDS_SECRET_NAME_PREFIX = 'storage-credentials-'

AZURE_FILES_SHARED_FOLDER = 'fairing-builds'

# This secret is required to be able to pull images from Azure Container Registry when creating new pods.
# To create a service principal and get its credentials we may do the following:
#    SUBSCRIPTION_ID=...
#    RESOURCE_GROUP=...
#    CONTAINER_REGISTRY_NAME=...
#    az ad sp create-for-rbac --scopes /subscriptions/${SUBSCRIPTION_ID}/resourceGroups/${RESOURCE_GROUP}/providers/Microsoft.ContainerRegistry/registries/${CONTAINER_REGISTRY_NAME}
# Then get the APP_ID and PASSWORD from the output of the previous command and pass them to the following:
#    NAMESPACE=...
#    SECRET_NAME=...
#    APP_ID=...
#    PASSWORD=...
#    YOUR_EMAIL=...
#    kubectl create secret docker-registry -n ${NAMESPACE} ${SECRET_NAME} --docker-server=${CONTAINER_REGISTRY_NAME}.azurecr.io --docker-username=${APP_ID} --docker-password=${PASSWORD} --docker-email=${YOUR_EMAIL}
# Then configure the serviceaccount to use this secret when pulling images from ACR:
#    kubectl patch serviceaccount default -n ${NAMESPACE} -p "{\"imagePullSecrets\": [{\"name\": \"${SECRET_NAME}\"}]}"
AZURE_ACR_CREDS_SECRET_NAME = 'acr-credentials'

# This configMap contains the Docker config required by a pod to be able to push images to Azure Container Registry.
# To generate this configMap we may copy the decoded contents of base64 string .dockerconfigjson in AZURE_ACR_CREDS_SECRET_NAME to a config.json file that we use here:
#    NAMESPACE=...
#    CONFIGMAP_NAME=...
#    kubectl create configmap -n ${NAMESPACE} ${CONFIGMAP_NAME} --from-file=config.json
#
# TODO ME Credentials are directly in this configMap and not stored as a secret. This is the only way we've found to make Kaniko pod able to access ACR without modifying Kaniko itself. Kaniko documention shows e.g. how to push to Amazon ECR using a config map and an Amazon ECR credential helper with credentials stored in a secret. Amazon ECR credential helper is built in to the Kaniko executor image, so if this is not a good way to pass credentials to the pod, then we have to modify Kaniko executor image to include ACR Docker Credential Helper and use a configMap + secret combination for Azure too.
AZURE_ACR_CONFIG_CONFIGMAP_NAME = 'acr-config'

DEFAULT_USER_AGENT = 'kubeflow-fairing/{VERSION}'
